{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3\n",
    "\n",
    "I hope you're getting the hang of things. Today we're introducing a new element, namely lectures by me on the prinicples of data visualization.\n",
    "\n",
    "*It's important for me to highlight that these lectures are quite important. We don't have a formal book on data visualization. So the only source of knowledge about the **principles**, **theories**, and **ideas**, that are the foundation for good data viz, comes from those videos*. So watch them ðŸ¤“\n",
    "\n",
    "I ramble on about that a bit more in the informal intro\n",
    "\n",
    "## Informal intro\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/KOuIqyVe6b8/0.jpg)](https://www.youtube.com/watch?v=KOuIqyVe6b8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # short video explaining the plans\n",
    "# from IPython.display import YouTubeVideo\n",
    "# YouTubeVideo(\"KOuIqyVe6b8\",width=600, height=333)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Once again, the lecture has three parts\n",
    "\n",
    "* First you will watch some videos on visualization. There are 2 videos, one with a general overview, then we get more specifc. \n",
    "* After that, we'll be reading about *scientific data visualization*, and the huge number of things you can do with just one variable. Naturally, we'll be answering questions about that book. \n",
    "* And finally reproducing some of those the plots from that book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Fundamentals of data visualization\n",
    "\n",
    "Find your headphones and get an intro to data visualization. \n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/9D2aI30AMhM/0.jpg)](https://www.youtube.com/watch?v=9D2aI30AMhM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Intro video\n",
    "# YouTubeVideo(\"9D2aI30AMhM\",width=800,height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Excercise:* Questions for the lecture\n",
    "> * What is the difference between *data* and *metadata*? How does that relate to the bike-example?\n",
    "> * Sune says that the human eye is a great tool for data analysis. Do you agree? Explain why/why not. Mention something that the human eye is very good at. Can you think of something that [is difficult for the human eye](http://cdn.ebaumsworld.com/mediaFiles/picture/718392/84732652.jpg). Explain why your example is difficult. \n",
    "> * Simpson's paradox is hard to explain. Come up with your own example - or find one on line.\n",
    "> * In your own words, explain the differnece between *exploratory* and *explanatory* data analysis. \n",
    "\n",
    "\n",
    "Next, something a bit more specific on data analysis. Digging a bit more into the theory.\n",
    "\n",
    "[![IMAGE ALT TEXT HERE](https://img.youtube.com/vi/yiU56codNlI/0.jpg)](https://www.youtube.com/watch?v=yiU56codNlI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YouTubeVideo(\"yiU56codNlI\",width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Excercise:* Questions for the lecture\n",
    "> * As mentioned earlier, visualization is not the only way to test for correlation. We can (for example) calculate the Pearson correlation. Explain in your own words how the Pearson correlation works and write down it's mathematical formulation. Can you think of an example where it fails (and visualization works)?\n",
    "> * What is the difference between a bar-chart and a histogram?\n",
    "> * I mention in the video that it's important to choose the right bin-size in histograms. But how do you do that? Do a Google search to find a criterion you like and explain it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Reading about the theory of visualization\n",
    "\n",
    "Since we can go deeper with the visualization this year, we are going to read the first couple of chapters from [*Data Analysis with Open Source Tools*](http://shop.oreilly.com/product/9780596802363.do). It's pretty old, but I think it's a fantastic ressource and one that is pretty much as relevant now as it was back then. The author is a physicist (like me) so I like the way he thinks. And the books takes the reader all the way from visualization, through modeling to computational mining. Anywho - it's a great book and well worth reading in its entirety. \n",
    "\n",
    "As part of this class we'll be reading the first chapters. Today, we'll read chaper 2 (28 pages) which supports and deepens many of the points I made during the first lecture (second video above). \n",
    "\n",
    "To find the text, you will need to go to **DTU Learn**. It's under \"Course content\" $\\rightarrow$ \"Lecture 3 reading\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Excercise*: Questions for DAOST\n",
    "> * Explain in your own words the point of the jitter plot.\n",
    "> * Explain in your own words the point of figure 2-3. (I'm going to skip saying \"in your own words\" going forward, but I hope you get the point; I expect all answers to be in your own words).\n",
    "> * The author of DAOST (Philipp Janert) likes KDEs (and think they're better than histograms). And I don't. I didn't give a detailed explanation in the video, but now that works to my advantage. I'll ask you guys to think about this and thereby create an excellent exercise: When can KDEs be misleading? (I'll provide the answer in a later lecture :)\n",
    "> * I've discussed some strengths of the CDF - there are also weaknesses. Janert writes \"CDFs have less intuitive appeal than histograms of KDEs\". What does he mean by that?\n",
    "> * What is a *Quantile plot*? What is it good for. \n",
    "> * How is a *Probablity plot* defined? What is it useful for? Have you ever seen one before?\n",
    "> * One of the reasons I like DAOST is that Janert is so suspicious of mean, median, and related summary statistics. Explain why one has to be careful when using those - and why visualization of the full data is always better. \n",
    "> * I love box plots. When are box plots most useful?\n",
    "> * The book doesn't mention [violin plots](https://en.wikipedia.org/wiki/Violin_plot). Are those better or worse than box plots? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: *Finally*! Let's create some visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Excercise*: Connecting the dots and recreating plots from DAOST but using our own favorite dataset.\n",
    "> * Let's make a jitter-plot (that is, code up something like **Figure 2-1** from DAOST from scratch), but based on SF Police data. My hunch from inspecting the file is that the police-folks might be a little bit lazy in noting down the **exact** time down to the second. So choose a crime-type and a suitable time interval (somewhere between a month and 6 months depending on the crime-type) and create a jitter plot of the arrest times during a single hour (like 13-14, for example). So let time run on the $x$-axis and create vertical jitter.\n",
    "> * Last time, we did lots bar-plots. Today, we'll play around with histograms (creating two crime-data based versions of the plot-type shown in DAOST **Figure 2-2**). I think the GPS data could be fun to see this way. \n",
    ">   * This time, pick two crime-types with different geographical patterns **and** a suitable time-interval for each (you want between 1000 and 10000 points in your histogram)\n",
    ">   * Then take the latitude part of the GPS coordinates for each crime and bin the latitudes so that you have around 50 bins across the city of SF. You can use your favorite method for binning. I like `numpy.histogram`. This function gives you the counts and then you do your own plotting. \n",
    "> * Next up is using the plot-type shown in **Figure 2-4** from DAOST, but with the data you used to create Figure 2.1. To create the kernel density plot, you can either use `gaussian_kde` from `scipy.stats` ([for an example, check out this stackoverflow post](https://stackoverflow.com/questions/4150171/how-to-create-a-density-plot-in-matplotlib)) or you can use [`seaborn.kdeplot`](https://seaborn.pydata.org/generated/seaborn.kdeplot.html).\n",
    "> * Now grab 25 random timepoints from the dataset (of 1000-10000 original data) you've just plotted and create a version of Figure 2-4 based on the 25 data points. Does this shed light on why I think KDEs can bee misleading? \n",
    ">\n",
    "> Let's take a break. Get some coffee or water. Stretch your legs. Talk to your friends for a bit. Breathe. Get relaxed so you're ready for the second part of the exercise. Ok. Now for more plots :)\n",
    ">\n",
    "> * Now we'll work on creating two versions of the plot in **Figure 2-11**, but using the GPS data you used for your version of Figure 2-2. Comment on the result. It is not easy to create this plot from scracth, Hint: Take a look at the `scipy.stats.probplot` function. \n",
    "> * OK, we're almost done, but we need some box plots. Here, I'd like you to use the box plots to visualize fluctuations of how many crimes happen per day. We'll use data from the 15 focus crimes defined last week.\n",
    ">   * For the full time-span of the data, calulate the **number of crimes per day** within each category for the entire duration of the data.\n",
    ">   * Create a box-and whiskers plot showing the mean, median, quantiles, etc for all 15 crime-types side-by-side. There are many ways to do this. I like to use [matplotlibs's built in functionality](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.boxplot.html)\n",
    ">   * What does this plot reveal that you can't see in the plots from last time?\n",
    "> * Also I want to show you guys another interesting use of box plots. To get started, let's calculate another average for each focus-crime, namely what time of day the crime happens. So this time, the distribution we want to plot is the average time-of-day that a crime takes place. There are many ways to do this, but let me describe one way to do it. \n",
    "    * For datapoint, the only thing you care about is the time-of-day, so discard everything else.\n",
    "    * You also have to deal with the fact that time is annoyingly not divided into nice units that go to 100 like many other numbers. I can think of two ways to deal with this.\n",
    "      * For each time-of-day, simply encode it as seconds since midnight.\n",
    "      * Or keep each whole hour, and convert the minute/second count to a percentage of an hour. So 10:15 $\\rightarrow$ 10.25, 8:40 $\\rightarrow$ 8.67, etc.\n",
    "    * Now you can create box-plots to create an overview of *when various crimes occur*. Note that these plot have quite a different interpretation than ones we created in the previous exercise. Cool, right?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
